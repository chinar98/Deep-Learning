{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_CNN_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdeumogwbYpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_sample_image \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUPe9hLodDEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load sample images\n",
        "china = load_sample_image(\"china.jpg\") /255\n",
        "flower = load_sample_image(\"flower.jpg\") /255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DOta_H_dRDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44d78288-1879-428c-e224-953505e55751"
      },
      "source": [
        "print(china.shape)\n",
        "print (flower.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(427, 640, 3)\n",
            "(427, 640, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHNdZPOGdTEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.array([china, flower])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwbP3EcfdhUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcdcd53c-e35b-497e-8b2a-d1724cbdcd09"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 427, 640, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3YIoDdwdjJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size, height, width, channels = images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qao5696zduDW",
        "colab_type": "text"
      },
      "source": [
        "We will now use Conv2D for easy processing of COnvolution <br> You can view the documentation here <br> https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "We need not define the filters ourselves. The network 'learns' the filters which best can give the desired classification output. We only need to specify how may filters we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJhkFA4AdmWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,padding=\"SAME\", activation=\"relu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V117xbbsn1Z9",
        "colab_type": "text"
      },
      "source": [
        "Above call implies the use of 32 filters which will result in a depth of 32 or 32 feature maps in the output layer <br> kernel_size = 3 implies use of a 3X3 filter, stides = 1 implies continuous scanning of input "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgRqv7htteZQ",
        "colab_type": "text"
      },
      "source": [
        "We now create a pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsqsEPJBfjOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_pool = keras.layers.MaxPool2D(pool_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1EYTaMss_yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}